{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8fcab9",
   "metadata": {},
   "source": [
    "# Tree Image Annotation with YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4fd90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc0984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from runs\\tree_canopy\\yolov8n-tree\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "weights_path = Path(\"runs/tree_canopy/yolov8n-tree/weights/best.pt\")\n",
    "if not weights_path.exists():\n",
    "    print(f\"Custom weights not found at {weights_path}, falling back to pretrained yolov8n.pt\")\n",
    "    weights_path = Path(\"yolov8n.pt\")\n",
    "model = YOLO(str(weights_path))\n",
    "names = model.names if isinstance(model.names, dict) else dict(enumerate(model.names))\n",
    "print(f\"Loaded model from {weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35396bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_trees_in_image(image_source, conf=0.25, imgsz=640, show=True, save_path=None):\n",
    "    \"\"\"Detect trees in a single image, draw green boxes, and optionally display/save the result.\"\"\"\n",
    "    results = model.predict(source=image_source, conf=conf, imgsz=imgsz, save=False, verbose=False)\n",
    "    if not results:\n",
    "        raise RuntimeError(\"Model did not return any predictions; verify the image source.\")\n",
    "    result = results[0]\n",
    "    if result.orig_img is not None:\n",
    "        annotated = result.orig_img.copy()\n",
    "    else:\n",
    "        if isinstance(image_source, (str, Path)):\n",
    "            image_path = Path(image_source)\n",
    "            annotated = cv2.imread(str(image_path))\n",
    "            if annotated is None:\n",
    "                raise FileNotFoundError(f\"Unable to read image from {image_path}\")\n",
    "        else:\n",
    "            raise ValueError(\"Provide a file path or an array-like image for prediction.\")\n",
    "    boxes = result.boxes\n",
    "    tree_count = 0\n",
    "    if boxes is not None and len(boxes) > 0:\n",
    "        xyxy = boxes.xyxy.cpu().numpy().astype(int)\n",
    "        confidences = boxes.conf.cpu().numpy()\n",
    "        class_ids = boxes.cls.cpu().numpy().astype(int)\n",
    "        tree_count = len(xyxy)\n",
    "        for (x1, y1, x2, y2), cls_id, conf_score in zip(xyxy, class_ids, confidences):\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = f\"{names.get(cls_id, 'tree')} {conf_score:.2f}\"\n",
    "            cv2.putText(annotated, label, (x1, max(y1 - 10, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    if save_path is not None:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        cv2.imwrite(str(save_path), annotated)\n",
    "    if show:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "        legend_patch = Patch(color=\"#00FF00\", label=f\"Trees detected: {tree_count}\")\n",
    "        plt.legend(handles=[legend_patch], loc=\"lower right\", frameon=True)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    return annotated, tree_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d891ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_trees_in_video(source, output_path, conf=0.25, imgsz=640, show=False):\n",
    "    \"\"\"Detect trees frame-by-frame from an OpenCV-readable source and save annotated MP4 output.\"\"\"\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video source {source}\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    output_path = Path(output_path).expanduser().resolve()\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    writer = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "    if not writer.isOpened():\n",
    "        cap.release()\n",
    "        raise RuntimeError(f\"Unable to create video writer at {output_path}\")\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            results = model.predict(source=frame, conf=conf, imgsz=imgsz, save=False, verbose=False)\n",
    "            annotated = frame.copy()\n",
    "            tree_count = 0\n",
    "            if results:\n",
    "                result = results[0]\n",
    "                boxes = result.boxes\n",
    "                if boxes is not None and len(boxes) > 0:\n",
    "                    xyxy = boxes.xyxy.cpu().numpy().astype(int)\n",
    "                    confidences = boxes.conf.cpu().numpy()\n",
    "                    class_ids = boxes.cls.cpu().numpy().astype(int)\n",
    "                    tree_count = len(xyxy)\n",
    "                    for (x1, y1, x2, y2), cls_id, conf_score in zip(xyxy, class_ids, confidences):\n",
    "                        cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        label = f\"{names.get(cls_id, 'tree')} {conf_score:.2f}\"\n",
    "                        cv2.putText(annotated, label, (x1, max(y1 - 10, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(annotated, f\"Trees: {tree_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            writer.write(annotated)\n",
    "            if show:\n",
    "                cv2.imshow(\"Tree Counter\", annotated)\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key in (ord('q'), 27):\n",
    "                    break\n",
    "        if show:\n",
    "            cv2.destroyAllWindows()\n",
    "    finally:\n",
    "        cap.release()\n",
    "        writer.release()\n",
    "    return str(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf73522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_unique_trees_in_video(source, output_path, conf=0.25, imgsz=640, show=False):\n",
    "    \"\"\"Detect and count each unique tree once using YOLO + built-in tracking.\"\"\"\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video source {source}\")\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    output_path = Path(output_path).expanduser().resolve()\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    writer = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "\n",
    "    if not writer.isOpened():\n",
    "        cap.release()\n",
    "        raise RuntimeError(f\"Unable to create video writer at {output_path}\")\n",
    "\n",
    "    seen_ids = set()  # To store unique track IDs\n",
    "    total_unique_trees = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Run detection + tracking in one step\n",
    "            results = model.track(source=frame, conf=conf, imgsz=imgsz, persist=True, verbose=False)\n",
    "\n",
    "            annotated = frame.copy()\n",
    "\n",
    "            if results and results[0].boxes is not None:\n",
    "                boxes = results[0].boxes\n",
    "                xyxy = boxes.xyxy.cpu().numpy().astype(int)\n",
    "                confidences = boxes.conf.cpu().numpy()\n",
    "                class_ids = boxes.cls.cpu().numpy().astype(int)\n",
    "                track_ids = boxes.id.cpu().numpy().astype(int) if boxes.id is not None else []\n",
    "\n",
    "                for (x1, y1, x2, y2), cls_id, conf_score, track_id in zip(xyxy, class_ids, confidences, track_ids):\n",
    "                    label = f\"Tree {track_id} ({conf_score:.2f})\"\n",
    "                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(annotated, label, (x1, max(y1 - 10, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "                    # Count each unique tree only once\n",
    "                    if track_id not in seen_ids:\n",
    "                        seen_ids.add(track_id)\n",
    "                        total_unique_trees += 1\n",
    "\n",
    "            cv2.putText(annotated, f\"Unique Trees: {total_unique_trees}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "\n",
    "            writer.write(annotated)\n",
    "            if show:\n",
    "                cv2.imshow(\"Tree Counter\", annotated)\n",
    "                if cv2.waitKey(1) & 0xFF in (ord('q'), 27):\n",
    "                    break\n",
    "\n",
    "        if show:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        writer.release()\n",
    "\n",
    "    return str(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855faf0e",
   "metadata": {},
   "source": [
    "# Usage\n",
    "- Run Cells 1-3 to load dependencies and the trained model weights.\n",
    "- `annotate_trees_in_image(\"/path/to/image.jpg\")` draws boxes and returns the annotated array and count.\n",
    "- `annotate_trees_in_video(\"/path/to/video.mp4\", \"./annotated.mp4\")` processes each frame, overlays the count, and saves an MP4.\n",
    "- Adjust `conf` or `imgsz` as needed for your imagery.\n",
    "- Pass `show=True` to preview video frames in a window (press `q`/`Esc` to quit early)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae2adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: annotate a single image\n",
    "# annotated_image, tree_total = annotate_trees_in_image(\"./test/hq720.jpg\", conf=0.25, imgsz=640, save_path=\"./annotatedJungleShot.jpg\")\n",
    "# print(f\"Trees detected: {tree_total}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47e5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: annotate a video and save as MP4\n",
    "# output_video_path = annotate_trees_in_video(\"./test.mp4\", \"./annotatedTestVideo.mp4\", conf=0.25, imgsz=640, show=False)\n",
    "# print(f\"Annotated video saved to: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f527b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING not enough matching points\n",
      "WARNING not enough matching points\n",
      "Annotated unique video saved to: D:\\TreeSense\\test\\annotatedTestVideo.mp4\n"
     ]
    }
   ],
   "source": [
    "# Exaple: annotate a video counting unique trees only once\n",
    "output_video_path = annotate_unique_trees_in_video(\"./test/test.mp4\", \"./test/annotatedTestVideo.mp4\", conf=0.25, imgsz=640, show=False)\n",
    "print(f\"Annotated unique video saved to: {output_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
